{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git init"
      ],
      "metadata": {
        "id": "QAj739moHX6Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "beee6346-5f3d-4c73-9604-e5e7b2926332"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mhint: Using 'master' as the name for the initial branch. This default branch name\u001b[m\n",
            "\u001b[33mhint: is subject to change. To configure the initial branch name to use in all\u001b[m\n",
            "\u001b[33mhint: of your new repositories, which will suppress this warning, call:\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: \tgit config --global init.defaultBranch <name>\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\u001b[m\n",
            "\u001b[33mhint: 'development'. The just-created branch can be renamed via this command:\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: \tgit branch -m <name>\u001b[m\n",
            "Initialized empty Git repository in /content/.git/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmy2IJIHHUqp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7245241c-8df8-419c-8846-a608132c9e9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'face_masking'...\n",
            "remote: Enumerating objects: 50, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 50 (delta 8), reused 19 (delta 4), pack-reused 25\u001b[K\n",
            "Receiving objects: 100% (50/50), 48.29 MiB | 17.56 MiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Klord02/face_masking.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd face_masking/"
      ],
      "metadata": {
        "id": "BHjJC5ttHdBt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d403c78-f2d5-446e-9b56-3726fecc1019"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/face_masking\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py"
      ],
      "metadata": {
        "id": "DVoloSP6Hg7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Till this part we use pretrained model to mask the image and collect the pixels value of different parts if face\n",
        "for better accuracy of the model we can also use add other features like nail,hands,fingers"
      ],
      "metadata": {
        "id": "VYNGch-uiFC0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "for eye_color and hair_color convert the pixels into array\n"
      ],
      "metadata": {
        "id": "1o_2pcZdKsvx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following code is a pipeline. The model that has been used in this pipeline has been implemented on random images as the data for the dataset is currently being accumulated. The model architecture and hyper-parameters will have to be finetuned according to the dataset later."
      ],
      "metadata": {
        "id": "vRjLUCwLlZ4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Traverse the directory structure to collect all 'eye_colors.txt' and 'hair_colors.txt' files\n",
        "root_directory = '/content/face_masking'  # Replace with the actual path to your result folder\n",
        "eye_txt_files = []\n",
        "hair_txt_files = []\n",
        "# add skin color\n",
        "skin_txt_files=[]\n",
        "lip_txt_files=[]\n",
        "\n",
        "\n",
        "for dirpath, dirnames, filenames in os.walk(root_directory):\n",
        "    for filename in filenames:\n",
        "        if filename == 'eye_colors.txt':\n",
        "            eye_txt_files.append(os.path.join(dirpath, filename))\n",
        "        elif filename == 'hair_colors.txt':\n",
        "            hair_txt_files.append(os.path.join(dirpath, filename))\n",
        "        elif filename == 'lip_colors.txt':\n",
        "            lip_txt_files.append(os.path.join(dirpath, filename))\n",
        "        elif filename == 'skin_colors.txt':\n",
        "            skin_txt_files.append(os.path.join(dirpath, filename))\n",
        "\n",
        "\n",
        "# Step 2, 3, and 4: Read, flatten, and organize the data into a dataset for eye colors\n",
        "eye_dataset = []\n",
        "lo = []\n",
        "\n",
        "for i in range(1, 101):\n",
        "    lo.append(i)\n",
        "eye_dataset.append(lo)\n",
        "\n",
        "for eye_txt_file in eye_txt_files:\n",
        "    # Read data from 'eye_colors.txt' and convert it into a NumPy array\n",
        "    with open(eye_txt_file, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "        data = [list(map(float, line.strip().split())) for line in lines]\n",
        "        data = np.array(data)\n",
        "\n",
        "        # Flatten the array and select the first 100 values\n",
        "        flattened_data = data.flatten()[:100]\n",
        "\n",
        "        # Add the flattened data to the eye_dataset\n",
        "        eye_dataset.append(flattened_data)\n",
        "\n",
        "# Convert the list of arrays into a NumPy array for eye colors\n",
        "eye_dataset = np.array(eye_dataset)\n",
        "\n",
        "# Step 2, 3, and 4: Read, flatten, and organize the data into a dataset for hair colors\n",
        "hair_dataset = []\n",
        "lo = []\n",
        "\n",
        "for i in range(1, 101):\n",
        "    lo.append(i)\n",
        "hair_dataset.append(lo)\n",
        "\n",
        "for hair_txt_file in hair_txt_files:\n",
        "    # Read data from 'hair_colors.txt' and convert it into a NumPy array\n",
        "    with open(hair_txt_file, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "        data = [list(map(float, line.strip().split())) for line in lines]\n",
        "        data = np.array(data)\n",
        "\n",
        "        # Flatten the array and select the first 100 values\n",
        "        flattened_data = data.flatten()[:100]\n",
        "\n",
        "        # Add the flattened data to the hair_dataset\n",
        "        hair_dataset.append(flattened_data)\n",
        "\n",
        "# Convert the list of arrays into a NumPy array for hair colors\n",
        "hair_dataset = np.array(hair_dataset)\n",
        "\n",
        "# for skin\n",
        "\n",
        "skin_dataset = []\n",
        "lo = []\n",
        "\n",
        "for i in range(1, 101):\n",
        "    lo.append(i)\n",
        "skin_dataset.append(lo)\n",
        "\n",
        "for skin_txt_file in skin_txt_files:\n",
        "    # Read data from 'skin_colors.txt' and convert it into a NumPy array\n",
        "    with open(skin_txt_file, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "        data = [list(map(float, line.strip().split())) for line in lines]\n",
        "        data = np.array(data)\n",
        "\n",
        "        # Flatten the array and select the first 100 values\n",
        "        flattened_data = data.flatten()[:100]\n",
        "\n",
        "        # Add the flattened data to the eye_dataset\n",
        "        skin_dataset.append(flattened_data)\n",
        "\n",
        "# Convert the list of arrays into a NumPy array for eye colors\n",
        "skin_dataset = np.array(skin_dataset)\n",
        "\n",
        "\n",
        "# for lips\n",
        "\n",
        "lip_dataset = []\n",
        "lo = []\n",
        "\n",
        "for i in range(1, 101):\n",
        "    lo.append(i)\n",
        "lip_dataset.append(lo)\n",
        "\n",
        "for lip_txt_file in lip_txt_files:\n",
        "    # Read data from 'skin_colors.txt' and convert it into a NumPy array\n",
        "    with open(lip_txt_file, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "        data = [list(map(float, line.strip().split())) for line in lines]\n",
        "        data = np.array(data)\n",
        "\n",
        "        # Flatten the array and select the first 100 values\n",
        "        flattened_data = data.flatten()[:100]\n",
        "\n",
        "        # Add the flattened data to the eye_dataset\n",
        "        lip_dataset.append(flattened_data)\n",
        "\n",
        "# Convert the list of arrays into a NumPy array for eye colors\n",
        "lip_dataset = np.array(skin_dataset)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "neWayYRcQE6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming 'dataset' is your NumPy array\n",
        "# Specify the path for the CSV file where you want to save the dataset\n",
        "csv_file_path1 = 'eye.csv'  # Replace with the desired file path\n",
        "csv_file_path2 = 'hair.csv'\n",
        "csv_file_path5 = 'skin.csv'\n",
        "csv_file_path6 = 'lip.csv'\n",
        "\n",
        "# Save the dataset to a CSV file\n",
        "np.savetxt(csv_file_path1, eye_dataset, delimiter=',', fmt='%f')\n",
        "np.savetxt(csv_file_path2, hair_dataset, delimiter=',', fmt='%f')\n",
        "np.savetxt(csv_file_path5, skin_dataset, delimiter=',', fmt='%f')\n",
        "np.savetxt(csv_file_path6, lip_dataset, delimiter=',', fmt='%f')\n"
      ],
      "metadata": {
        "id": "WgPi_SIKDwMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lo1=[]\n",
        "for i in range(1, 501):\n",
        "    lo1.append(i)"
      ],
      "metadata": {
        "id": "Z01l1LU_QE1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "for brow_mask"
      ],
      "metadata": {
        "id": "AY-ug2oEKozs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# Step 1: Specify the path to the root directory\n",
        "root_directory = '/content/face_masking/res/test_res'  # Replace with the actual path to your root folder\n",
        "\n",
        "# Step 2: Navigate through the folder structure to find 'brow_mask.png' files\n",
        "brow_mask_files = []\n",
        "\n",
        "for subdir, dirs, files in os.walk(root_directory):\n",
        "    for file in files:\n",
        "        if file == 'brow_mask.png':\n",
        "            brow_mask_files.append(os.path.join(subdir, file))\n",
        "\n",
        "# Step 3: Convert 'brow_mask.png' images to flattened NumPy arrays and organize them into a dataset\n",
        "brow_mask_dataset = []\n",
        "brow_mask_dataset.append(lo1)\n",
        "\n",
        "for brow_mask_file in brow_mask_files:\n",
        "    # Read and convert the image into a NumPy array\n",
        "    img = Image.open(brow_mask_file)\n",
        "    img_array = np.array(img)\n",
        "\n",
        "    # Flatten the array\n",
        "    flattened_array = img_array.flatten()\n",
        "\n",
        "    # Set a threshold for excluding pixels close to black\n",
        "    threshold = 10  # Adjust this threshold as needed\n",
        "\n",
        "    # Exclude pixels close to black\n",
        "    color_part = flattened_array[flattened_array > threshold]\n",
        "\n",
        "    # Take only the first 500 values\n",
        "    color_part_first_500 = color_part[:500]\n",
        "\n",
        "    # Add the color part to the brow_mask_dataset\n",
        "    brow_mask_dataset.append(color_part_first_500)\n",
        "\n",
        "# Convert the list of arrays into a NumPy array for color parts\n",
        "brow_mask_dataset = np.array(brow_mask_dataset)\n"
      ],
      "metadata": {
        "id": "mWqdjBRFIIy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "brow_mask_dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7oT1zTSP24w",
        "outputId": "53725f49-6737-4672-b0e1-c652a8d10c4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 500)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "for ear_mask"
      ],
      "metadata": {
        "id": "a_HrF6rdOPlu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# Step 1: Specify the path to the root directory\n",
        "root_directory = '/content/face_masking/res/test_res'  # Replace with the actual path to your root folder\n",
        "\n",
        "# Step 2: Navigate through the folder structure to find 'brow_mask.png' files\n",
        "ear_mask_files = []\n",
        "\n",
        "for subdir, dirs, files in os.walk(root_directory):\n",
        "    for file in files:\n",
        "        if file == 'ear_mask.png':\n",
        "            ear_mask_files.append(os.path.join(subdir, file))\n",
        "\n",
        "# Step 3: Convert 'brow_mask.png' images to flattened NumPy arrays and organize them into a dataset\n",
        "ear_mask_dataset = []\n",
        "ear_mask_dataset.append(lo1)\n",
        "\n",
        "for ear_mask_file in ear_mask_files:\n",
        "    # Read and convert the image into a NumPy array\n",
        "    img = Image.open(ear_mask_file)\n",
        "    img_array = np.array(img)\n",
        "\n",
        "    # Flatten the array\n",
        "    flattened_array = img_array.flatten()\n",
        "\n",
        "    # Set a threshold for excluding pixels close to black\n",
        "    threshold = 10  # Adjust this threshold as needed\n",
        "\n",
        "    # Exclude pixels close to black\n",
        "    color_part = flattened_array[flattened_array > threshold]\n",
        "\n",
        "    # Take only the first 500 values\n",
        "    color_part_first_500 = color_part[:500]\n",
        "\n",
        "    # Add the color part to the brow_mask_dataset\n",
        "    ear_mask_dataset.append(color_part_first_500)\n",
        "\n",
        "# Convert the list of arrays into a NumPy array for color parts\n",
        "ear_mask_dataset = np.array(ear_mask_dataset)"
      ],
      "metadata": {
        "id": "-kLaA7_bORN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ear_mask_dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QGNHwZROvq3",
        "outputId": "5da8db68-5f74-4bdf-8ec3-e419359d47f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 500)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming 'dataset' is your NumPy array\n",
        "# Specify the path for the CSV file where you want to save the dataset\n",
        "csv_file_path3 = 'brow_mask.csv'  # Replace with the desired file path\n",
        "csv_file_path4 = 'ear_mask.csv'\n",
        "\n",
        "# Save the dataset to a CSV file\n",
        "np.savetxt(csv_file_path3, brow_mask_dataset, delimiter=',', fmt='%f')\n",
        "np.savetxt(csv_file_path4, ear_mask_dataset, delimiter=',', fmt='%f')\n"
      ],
      "metadata": {
        "id": "hxr2DhZTIN5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df1=pd.read_csv(\"/content/face_masking/brow_mask.csv\")\n",
        "df2=pd.read_csv(\"/content/face_masking/ear_mask.csv\")\n",
        "df3=pd.read_csv(\"/content/face_masking/eye.csv\")\n",
        "df4=pd.read_csv(\"/content/face_masking/hair.csv\")\n",
        "df5=pd.read_csv(\"/content/face_masking/skin.csv\")\n",
        "df6=pd.read_csv(\"/content/face_masking/lip.csv\")"
      ],
      "metadata": {
        "id": "VSLpYkl7Ct1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = pd.concat([df1,df2,df3,df4,df5,df6], axis=1)"
      ],
      "metadata": {
        "id": "xW76FAoPGCrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_column_names = list(range(1, len(merged_df.columns) + 1))\n",
        "\n",
        "# Assign the new column names to the DataFrame\n",
        "merged_df.columns = new_column_names\n"
      ],
      "metadata": {
        "id": "7NgfJx3VHFnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(merged_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_xH1G1jYE9w",
        "outputId": "f2b44ac8-3aae-4887-bf70-4201808b3f85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fgi1MquGiMR_",
        "outputId": "87e20529-54ab-422a-fec4-9f2a69a2a66b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 1400)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df['target'] = np.random.randint(0,2, size=(len(merged_df),))\n",
        "\n",
        "# Split the dataset into features (X) and target labels (y)\n",
        "X = merged_df.drop('target', axis=1)\n",
        "y = merged_df['target']\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ONXjlPajZ7tG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6-kOOkzyavPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(16, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(8, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(4, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(2, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "IG1mSnIQ7Sf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "b3QWPXeAnJui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model, to_file='model_architecture.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "QX6b2DxW7hi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
        "print(f'Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "id": "ahsq-V3m7Z_J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}